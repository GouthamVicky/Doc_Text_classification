{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model selection is the task of selecting a statistical model from a set of candidate models, given data. In the simplest cases, a pre-existing set of data is considered. Given candidate models of similar predictive or explanatory power, the simplest model is most likely to be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is available in Google BigQuery that can be downloaded from here. The data is also publicly available at this Cloud Storage URL: https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from gensim) (1.5.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from gensim) (4.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from gensim) (1.18.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from gensim) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>are unique identification authority of india t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>andis unique identification authority of india...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>ard 4641 hrd unique identification authority o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>hdo'd government of india jddlo fifur hargun s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>unique identification authority of india 9di: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>uniqui idei ntif ication nuthorvyof-india addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>unique identification authority of india ane a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>7/40/ble 14 utille wot â‚¬iss sl6s nah 9661/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>government of india aadhaar ard 311817 4e917 n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aadhar</td>\n",
       "      <td>- government of indja wandor arjun kumar shaw ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0   aadhar  are unique identification authority of india t...\n",
       "1   aadhar  andis unique identification authority of india...\n",
       "2   aadhar  ard 4641 hrd unique identification authority o...\n",
       "3   aadhar  hdo'd government of india jddlo fifur hargun s...\n",
       "4   aadhar  unique identification authority of india 9di: ...\n",
       "5   aadhar  uniqui idei ntif ication nuthorvyof-india addr...\n",
       "6   aadhar  unique identification authority of india ane a...\n",
       "7   aadhar  7/40/ble 14 utille wot â‚¬iss sl6s nah 9661/10...\n",
       "8   aadhar  government of india aadhaar ard 311817 4e917 n...\n",
       "9   aadhar  - government of indja wandor arjun kumar shaw ..."
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/finaldata.csv')\n",
    "df = df[pd.notnull(df['category'])]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1458045"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have over 10 million words in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['bankStatement','passport','electricityBill','phoneBill','pan','drivingLicense','aadhar','bankPassbook','rentalAgreement']\n",
    "plt.figure(figsize=(10,4))\n",
    "df.category.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = df[df.index == index][['text', 'category']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Tag:', example[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look a few post and tag pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrd government of india ramprasath perumal dob: 25/08/1987 91,5001 / male 6528 8440 3803 \n",
      "Tag: aadhar\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "government of india aadhaar hrd hran te917 ot 741Â°t n. ft 789 unique identification authority of india 96717 ot thin 317-41157 gri sta d i government of india te (o) sitterft the grt all 97#1 aih enrolment no.: 0000/00280/19073 information to aadhaar is a proof of identity, not of citizenship. trit to establish identity, authenticate online. naresh mali maliyon ki dhani this is electronically generated letter. bhinmal bhinmal 3itetr der str ai hou fice i jalor rajasthan - 343029 8879024962 31teir ai 3ile of 301d # 342100 i aadhaar is valid throughout the country . aadhaar will be helpful in availing government and non-government services in future . signature not verified india 03 cation 15:26:32 / your aadhaar no. : 6656 3779 8086 #2t 3iteir #a 482101 x hrd government of india unique identification authority of india address: ttt: t #17f maliyon ki dhani, bhinmal, jalor, # a grir, naresh mali rajasthan 343029 pigfett 343029 g-t aft/dob: 11/03/1994 954/ male 6656 3779 8086 6656 3779 8086 or #2t 3iteir #2 482101 dm www help & uidai gov.in www. gov. in \n",
      "Tag: aadhar\n"
     ]
    }
   ],
   "source": [
    "print_plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text need to be cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hrd government india ramprasath perumal dob 25 08 1987 91 5001 male 6528 8440 3803\n",
      "Tag: aadhar\n"
     ]
    }
   ],
   "source": [
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Way better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1288189"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have over 3 million words to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.category\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps includes feature engineering. We will convert our text documents to a matrix of token counts (CountVectorizer), then transform a count matrix to a normalized tf-idf representation (tf-idf transformer). After that, we train several classifiers. \n",
    "\n",
    "### Naive Bayes classifier for multinomial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bankStatement', 'passport', 'electricityBill', 'phoneBill', 'pan', 'drivingLicense', 'aadhar', 'bankPassbook', 'rentalAgreement']\n",
      "accuracy 0.921372719374457\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  bankStatement       0.99      0.95      0.97       230\n",
      "       passport       0.99      0.51      0.68       177\n",
      "electricityBill       0.77      0.99      0.86       369\n",
      "      phoneBill       0.99      0.99      0.99       204\n",
      "            pan       0.89      0.96      0.92       300\n",
      " drivingLicense       0.99      0.96      0.97       273\n",
      "         aadhar       0.95      0.99      0.97       322\n",
      "   bankPassbook       0.97      0.90      0.93       267\n",
      "rentalAgreement       0.99      0.84      0.91       160\n",
      "\n",
      "       accuracy                           0.92      2302\n",
      "      macro avg       0.95      0.90      0.91      2302\n",
      "   weighted avg       0.93      0.92      0.92      2302\n",
      "\n",
      "CPU times: user 383 ms, sys: 0 ns, total: 383 ms\n",
      "Wall time: 382 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(my_tags)\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9578627280625543\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  bankStatement       0.95      0.98      0.96       230\n",
      "       passport       0.96      0.84      0.90       177\n",
      "electricityBill       0.89      0.98      0.94       369\n",
      "      phoneBill       0.98      0.99      0.98       204\n",
      "            pan       0.97      0.96      0.96       300\n",
      " drivingLicense       0.99      0.96      0.97       273\n",
      "         aadhar       0.97      0.99      0.98       322\n",
      "   bankPassbook       0.97      0.95      0.96       267\n",
      "rentalAgreement       0.99      0.91      0.95       160\n",
      "\n",
      "       accuracy                           0.96      2302\n",
      "      macro avg       0.96      0.95      0.96      2302\n",
      "   weighted avg       0.96      0.96      0.96      2302\n",
      "\n",
      "CPU times: user 368 ms, sys: 7.66 ms, total: 375 ms\n",
      "Wall time: 375 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=100000.0, n_jobs=1))])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
    "               ])\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9674196350999131\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  bankStatement       0.99      0.97      0.98       230\n",
      "       passport       0.95      0.95      0.95       177\n",
      "electricityBill       0.97      0.96      0.97       369\n",
      "      phoneBill       0.98      0.99      0.98       204\n",
      "            pan       0.95      0.97      0.96       300\n",
      " drivingLicense       0.99      0.96      0.98       273\n",
      "         aadhar       0.92      0.99      0.96       322\n",
      "   bankPassbook       0.98      0.97      0.98       267\n",
      "rentalAgreement       0.99      0.93      0.96       160\n",
      "\n",
      "       accuracy                           0.97      2302\n",
      "      macro avg       0.97      0.97      0.97      2302\n",
      "   weighted avg       0.97      0.97      0.97      2302\n",
      "\n",
      "CPU times: user 408 ms, sys: 0 ns, total: 408 ms\n",
      "Wall time: 408 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/logreg_text_classification.pkl']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import joblib\n",
    "from joblib import dump\n",
    "\n",
    "# dump the pipeline model\n",
    "dump(logreg, filename=\"models/logreg_text_classification.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['passport']\n",
      "<class 'numpy.ndarray'>\n",
      "['passport'] <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import load\n",
    "\n",
    "# sample tweet text\n",
    "text = [\"/ uatray foren / / name of father / legal guardian l5982212 goutam kumar datta wiren 051 / name of mother lipika datta ufa 2011 yean / name of spouse /address 15, bharati niketan,2nd crs, manjunatha lyt anandpura kr puram, bangalore pin: 560036, karnataka, india gerÃ¡ en - afte elt para / old passport no. with date and place of issue no. bn2067263296713 \"]\n",
    "\n",
    "# load the saved pipleine model\n",
    "logregmodel = load(\"models/logreg_text_classification.pkl\")\n",
    "\n",
    "# predict on the sample tweet text\n",
    "prediction=logregmodel.predict(text)\n",
    "print(prediction)\n",
    "print(type(prediction))\n",
    "class_list=prediction.tolist()\n",
    "print(class_list,type(class_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common way is to average the two word vectors. BOW based approaches which includes averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2vec, taking the linear combination of every term in the document creates a random walk with bias process in the word2vec space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim \n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.text, df.category, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['bureau', 'e', 'turiou', 'republic', 'india', 'country', 'code', 'passport', 'p', 'ind', 'h', '4744495', '34114', 'surname', 'perumal', '451', 'name', 'father', 'legal', 'guardian', 'perumal', 'bharath', 'fern', 'given', 'name', 'anantha', 'krishna', '45t', 'name', 'mother', 'nationality', 'fein', 'sex', 'birth', 'perumal', 'kaustubha', 'indian', '14', '12', '1988', 'una', '451', 'name', 'spouse', 'place', 'birth', 'ramachandrapuram', 'gitr', 'set', '451', 'frith', 'place', 'issue', 'hig', '373', 'road', '11', 'phase1', 'hyderabad', 'bath', 'extension', 'bhel', 'ramachandrapuram', 'gitr', 'axx', 'fara', 'date', 'issue', 'un', 'fara', 'date', 'expiry', '04', '08', '2009', '03', '08', '2019', 'hyderabad', '502032', '451', 'gitr', 'fara', 'vzi', 'old', 'passport', 'date', 'place', 'issue', 'file', 'hyda03487309', 'smanths'], tags=['Train_0']),\n",
       " TaggedDocument(words=['airtel', 'relationship', 'number', '1029581857', 'airtel', 'mobile', 'number', '9910992176', 'charges', 'detail', '9910992176', 'monthly', 'rentals', 'description', 'date', 'date', 'rental', 'net', 'charges', 'total', 'plan', 'name', '64900', 'family', 'infinity', 'plan', '649', '23', '01', '2020', '22', '02', '2020', '64900', '64900', 'usage', '23jan2020', '22feb2020', 'total', 'usage', 'description', 'number', 'tariff', 'usage', 'charges', 'net', 'charges', 'total', 'pulse', 'internet', 'mb', '000', '4g', '3g', '2g', 'mobile', 'internet', '459368', '470393', '1p', '10kb', '000', '000', 'pulses', 'mb', 'conversion', 'pulse', '10', '1024', 'charging', 'done', 'per', '10', 'kb', 'internet', 'charges', 'may', 'vary', 'due', 'usage', 'multiple', 'data', 'bands', '2g', '3g', '4g', 'tax', 'details', 'description', 'amount', 'total', 'tax', '11682', '11682', 'months', 'charges', '76582', 'tariff', 'plan', 'benefits', 'call', 'rates', 'local', 'std', 'sms', 'rates', 'local', 'national', 'airtel', 'mobile', '00', 'min', '00', 'min', 'local', 'national', '1', 'msg', '15', 'msg', 'mobile', '00', 'min', '00', 'min', 'national', 'roaming', '025', 'msg', '038', 'msg', 'international', '5', 'msg', '5', 'msg', 'landline', '00', 'min', '00', 'min', 'airtel', 'cug', '00', 'min', '00', 'min', 'video', 'call', '005', 'sec', '005', 'sec', 'data', 'conversion', '1mb', '1', '024kb', '1gb1', '024mb', '1', '048', '576kb', 'roaming', 'isd', 'plans', 'tariff', 'visit', 'wwwairtelin', '27jul2015', 'page', '3', '6'], tags=['Train_1'])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7672/7672 [00:00<00:00, 920417.04it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7672/7672 [00:00<00:00, 992342.81it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 936243.83it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 988046.56it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 981297.28it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 972812.75it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 945431.32it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 951413.29it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 995135.46it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 988228.62it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 984268.81it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 991731.14it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 987743.27it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 971373.81it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 961333.02it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 1010923.32it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 971197.91it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 982795.81it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 956731.29it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 982225.83it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 978284.14it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 978284.14it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 742573.97it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 978373.37it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 977600.57it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 956788.19it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 981237.43it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 984871.31it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 998594.22it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 997016.28it/s]\n",
      "100%|██████████| 7672/7672 [00:00<00:00, 992128.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, n_jobs=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9218071242397915\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  bankStatement       0.93      0.95      0.94       225\n",
      "       passport       0.83      0.81      0.82       176\n",
      "electricityBill       0.92      0.92      0.92       347\n",
      "      phoneBill       0.88      0.96      0.92       216\n",
      "            pan       0.95      0.96      0.96       314\n",
      " drivingLicense       0.94      0.91      0.93       243\n",
      "         aadhar       0.97      0.93      0.95       333\n",
      "   bankPassbook       0.92      0.92      0.92       274\n",
      "rentalAgreement       0.89      0.89      0.89       174\n",
      "\n",
      "       accuracy                           0.92      2302\n",
      "      macro avg       0.92      0.92      0.92      2302\n",
      "   weighted avg       0.92      0.92      0.92      2302\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 5370\n",
      "Test size: 2302\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(df) * .7)\n",
    "print (\"Train size: %d\" % train_size)\n",
    "print (\"Test size: %d\" % (len(df) - train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pan', 'aadhar', 'phoneBill', 'drivingLicense', 'bankStatement', 'passport', 'electricityBill', 'rentalAgreement', 'bankPassbook'}\n",
      "{'pan', 'aadhar', 'phoneBill', 'drivingLicense', 'bankStatement', 'passport', 'electricityBill', 'rentalAgreement', 'bankPassbook'}\n"
     ]
    }
   ],
   "source": [
    "train_posts = df['text']\n",
    "train_tags = df['category']\n",
    "test_posts = df['text']\n",
    "test_tags = df['category']\n",
    "print(set(train_tags))\n",
    "print(set(test_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (7672, 1000)\n",
      "x_test shape: (7672, 1000)\n",
      "y_train shape: (7672, 9)\n",
      "y_test shape: (7672, 9)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs =100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6904 samples, validate on 768 samples\n",
      "Epoch 1/100\n",
      "6904/6904 [==============================] - 2s 219us/step - loss: 0.3426 - accuracy: 0.9277 - val_loss: 5.1186 - val_accuracy: 0.2513\n",
      "Epoch 2/100\n",
      "6904/6904 [==============================] - 1s 196us/step - loss: 0.1297 - accuracy: 0.9719 - val_loss: 5.8108 - val_accuracy: 0.2513\n",
      "Epoch 3/100\n",
      "6904/6904 [==============================] - 1s 177us/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 6.4840 - val_accuracy: 0.2500\n",
      "Epoch 4/100\n",
      "6904/6904 [==============================] - 1s 189us/step - loss: 0.0753 - accuracy: 0.9819 - val_loss: 6.9144 - val_accuracy: 0.2513\n",
      "Epoch 5/100\n",
      "6904/6904 [==============================] - 2s 249us/step - loss: 0.0635 - accuracy: 0.9852 - val_loss: 7.4891 - val_accuracy: 0.2513\n",
      "Epoch 6/100\n",
      "6904/6904 [==============================] - 1s 185us/step - loss: 0.0630 - accuracy: 0.9870 - val_loss: 7.6297 - val_accuracy: 0.2513\n",
      "Epoch 7/100\n",
      "6904/6904 [==============================] - 1s 189us/step - loss: 0.0419 - accuracy: 0.9900 - val_loss: 8.0585 - val_accuracy: 0.2513\n",
      "Epoch 8/100\n",
      "6904/6904 [==============================] - 1s 185us/step - loss: 0.0460 - accuracy: 0.9893 - val_loss: 8.3833 - val_accuracy: 0.2513\n",
      "Epoch 9/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0441 - accuracy: 0.9904 - val_loss: 8.3886 - val_accuracy: 0.2513\n",
      "Epoch 10/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0392 - accuracy: 0.9909 - val_loss: 8.7749 - val_accuracy: 0.2513\n",
      "Epoch 11/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0383 - accuracy: 0.9913 - val_loss: 8.9671 - val_accuracy: 0.2513\n",
      "Epoch 12/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0337 - accuracy: 0.9909 - val_loss: 8.9480 - val_accuracy: 0.2513\n",
      "Epoch 13/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0345 - accuracy: 0.9907 - val_loss: 9.3118 - val_accuracy: 0.2513\n",
      "Epoch 14/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0351 - accuracy: 0.9915 - val_loss: 9.3811 - val_accuracy: 0.2513\n",
      "Epoch 15/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0292 - accuracy: 0.9920 - val_loss: 9.7782 - val_accuracy: 0.2513\n",
      "Epoch 16/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0346 - accuracy: 0.9929 - val_loss: 9.8822 - val_accuracy: 0.2513\n",
      "Epoch 17/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 10.0523 - val_accuracy: 0.2513\n",
      "Epoch 18/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0350 - accuracy: 0.9916 - val_loss: 10.1080 - val_accuracy: 0.2513\n",
      "Epoch 19/100\n",
      "6904/6904 [==============================] - 1s 180us/step - loss: 0.0314 - accuracy: 0.9919 - val_loss: 9.8630 - val_accuracy: 0.2513\n",
      "Epoch 20/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0320 - accuracy: 0.9913 - val_loss: 10.3949 - val_accuracy: 0.2513\n",
      "Epoch 21/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0349 - accuracy: 0.9922 - val_loss: 10.5096 - val_accuracy: 0.2513\n",
      "Epoch 22/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 10.3671 - val_accuracy: 0.2526\n",
      "Epoch 23/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0280 - accuracy: 0.9935 - val_loss: 10.4250 - val_accuracy: 0.2513\n",
      "Epoch 24/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 11.0550 - val_accuracy: 0.2526\n",
      "Epoch 25/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0274 - accuracy: 0.9929 - val_loss: 11.2271 - val_accuracy: 0.2526\n",
      "Epoch 26/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0231 - accuracy: 0.9932 - val_loss: 11.1644 - val_accuracy: 0.2513\n",
      "Epoch 27/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0243 - accuracy: 0.9930 - val_loss: 11.1435 - val_accuracy: 0.2513\n",
      "Epoch 28/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0296 - accuracy: 0.9938 - val_loss: 11.2554 - val_accuracy: 0.2513\n",
      "Epoch 29/100\n",
      "6904/6904 [==============================] - 1s 186us/step - loss: 0.0315 - accuracy: 0.9925 - val_loss: 11.1977 - val_accuracy: 0.2526\n",
      "Epoch 30/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0291 - accuracy: 0.9932 - val_loss: 11.7733 - val_accuracy: 0.2526\n",
      "Epoch 31/100\n",
      "6904/6904 [==============================] - 1s 177us/step - loss: 0.0295 - accuracy: 0.9935 - val_loss: 11.4306 - val_accuracy: 0.2513\n",
      "Epoch 32/100\n",
      "6904/6904 [==============================] - 1s 179us/step - loss: 0.0333 - accuracy: 0.9920 - val_loss: 11.8537 - val_accuracy: 0.2513\n",
      "Epoch 33/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0257 - accuracy: 0.9932 - val_loss: 11.9717 - val_accuracy: 0.2526\n",
      "Epoch 34/100\n",
      "6904/6904 [==============================] - 1s 179us/step - loss: 0.0260 - accuracy: 0.9932 - val_loss: 12.1899 - val_accuracy: 0.2513\n",
      "Epoch 35/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0283 - accuracy: 0.9933 - val_loss: 12.2513 - val_accuracy: 0.2513\n",
      "Epoch 36/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0248 - accuracy: 0.9936 - val_loss: 12.6085 - val_accuracy: 0.2435\n",
      "Epoch 37/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 12.8992 - val_accuracy: 0.2513\n",
      "Epoch 38/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0242 - accuracy: 0.9930 - val_loss: 13.1661 - val_accuracy: 0.2513\n",
      "Epoch 39/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 13.2897 - val_accuracy: 0.2513\n",
      "Epoch 40/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0241 - accuracy: 0.9932 - val_loss: 13.7121 - val_accuracy: 0.2513\n",
      "Epoch 41/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0261 - accuracy: 0.9936 - val_loss: 13.7520 - val_accuracy: 0.2526\n",
      "Epoch 42/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 14.5023 - val_accuracy: 0.2513\n",
      "Epoch 43/100\n",
      "6904/6904 [==============================] - 1s 180us/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 14.1765 - val_accuracy: 0.2526\n",
      "Epoch 44/100\n",
      "6904/6904 [==============================] - 1s 186us/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 14.8147 - val_accuracy: 0.2513\n",
      "Epoch 45/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0219 - accuracy: 0.9935 - val_loss: 15.1325 - val_accuracy: 0.2513\n",
      "Epoch 46/100\n",
      "6904/6904 [==============================] - 1s 168us/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 15.0219 - val_accuracy: 0.2526\n",
      "Epoch 47/100\n",
      "6904/6904 [==============================] - 1s 166us/step - loss: 0.0260 - accuracy: 0.9933 - val_loss: 15.1892 - val_accuracy: 0.2526\n",
      "Epoch 48/100\n",
      "6904/6904 [==============================] - 1s 170us/step - loss: 0.0224 - accuracy: 0.9948 - val_loss: 16.0575 - val_accuracy: 0.2487\n",
      "Epoch 49/100\n",
      "6904/6904 [==============================] - 1s 170us/step - loss: 0.0272 - accuracy: 0.9932 - val_loss: 16.1426 - val_accuracy: 0.2526\n",
      "Epoch 50/100\n",
      "6904/6904 [==============================] - 1s 168us/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 16.5636 - val_accuracy: 0.2526\n",
      "Epoch 51/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 16.6588 - val_accuracy: 0.2526\n",
      "Epoch 52/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0253 - accuracy: 0.9939 - val_loss: 16.8781 - val_accuracy: 0.2526\n",
      "Epoch 53/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0262 - accuracy: 0.9935 - val_loss: 17.5013 - val_accuracy: 0.2526\n",
      "Epoch 54/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0339 - accuracy: 0.9935 - val_loss: 18.1162 - val_accuracy: 0.2526\n",
      "Epoch 55/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0201 - accuracy: 0.9944 - val_loss: 18.2899 - val_accuracy: 0.2526\n",
      "Epoch 56/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 19.2192 - val_accuracy: 0.2526\n",
      "Epoch 57/100\n",
      "6904/6904 [==============================] - 1s 175us/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 19.2275 - val_accuracy: 0.2526\n",
      "Epoch 58/100\n",
      "6904/6904 [==============================] - 1s 185us/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 19.1325 - val_accuracy: 0.2526\n",
      "Epoch 59/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0244 - accuracy: 0.9936 - val_loss: 19.2367 - val_accuracy: 0.2526\n",
      "Epoch 60/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0230 - accuracy: 0.9942 - val_loss: 18.9701 - val_accuracy: 0.2526\n",
      "Epoch 61/100\n",
      "6904/6904 [==============================] - 1s 170us/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 19.1057 - val_accuracy: 0.2526\n",
      "Epoch 62/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 19.7466 - val_accuracy: 0.2526\n",
      "Epoch 63/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0257 - accuracy: 0.9936 - val_loss: 19.9320 - val_accuracy: 0.2526\n",
      "Epoch 64/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 20.3961 - val_accuracy: 0.2526\n",
      "Epoch 65/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0236 - accuracy: 0.9941 - val_loss: 20.9150 - val_accuracy: 0.2526\n",
      "Epoch 66/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0225 - accuracy: 0.9945 - val_loss: 21.1101 - val_accuracy: 0.2526\n",
      "Epoch 67/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0297 - accuracy: 0.9930 - val_loss: 21.5472 - val_accuracy: 0.2526\n",
      "Epoch 68/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0223 - accuracy: 0.9946 - val_loss: 21.7790 - val_accuracy: 0.2513\n",
      "Epoch 69/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 22.4078 - val_accuracy: 0.2513\n",
      "Epoch 70/100\n",
      "6904/6904 [==============================] - 1s 179us/step - loss: 0.0261 - accuracy: 0.9944 - val_loss: 22.6501 - val_accuracy: 0.2513\n",
      "Epoch 71/100\n",
      "6904/6904 [==============================] - 1s 169us/step - loss: 0.0247 - accuracy: 0.9946 - val_loss: 22.4814 - val_accuracy: 0.2526\n",
      "Epoch 72/100\n",
      "6904/6904 [==============================] - 1s 170us/step - loss: 0.0244 - accuracy: 0.9945 - val_loss: 23.1011 - val_accuracy: 0.2526\n",
      "Epoch 73/100\n",
      "6904/6904 [==============================] - 1s 171us/step - loss: 0.0225 - accuracy: 0.9936 - val_loss: 23.8247 - val_accuracy: 0.2526\n",
      "Epoch 74/100\n",
      "6904/6904 [==============================] - 1s 172us/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 23.9764 - val_accuracy: 0.2526\n",
      "Epoch 75/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0230 - accuracy: 0.9951 - val_loss: 24.0352 - val_accuracy: 0.2526\n",
      "Epoch 76/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 24.6808 - val_accuracy: 0.2526\n",
      "Epoch 77/100\n",
      "6904/6904 [==============================] - 1s 173us/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 24.9957 - val_accuracy: 0.2526\n",
      "Epoch 78/100\n",
      "6904/6904 [==============================] - 1s 185us/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 24.7182 - val_accuracy: 0.2526\n",
      "Epoch 79/100\n",
      "6904/6904 [==============================] - 1s 186us/step - loss: 0.0244 - accuracy: 0.9945 - val_loss: 25.3241 - val_accuracy: 0.2500\n",
      "Epoch 80/100\n",
      "6904/6904 [==============================] - 1s 201us/step - loss: 0.0260 - accuracy: 0.9945 - val_loss: 25.7528 - val_accuracy: 0.2526\n",
      "Epoch 81/100\n",
      "6904/6904 [==============================] - 1s 213us/step - loss: 0.0212 - accuracy: 0.9942 - val_loss: 25.8778 - val_accuracy: 0.2526\n",
      "Epoch 82/100\n",
      "6904/6904 [==============================] - 1s 186us/step - loss: 0.0292 - accuracy: 0.9930 - val_loss: 26.3645 - val_accuracy: 0.2526\n",
      "Epoch 83/100\n",
      "6904/6904 [==============================] - 1s 178us/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 27.0541 - val_accuracy: 0.2461\n",
      "Epoch 84/100\n",
      "6904/6904 [==============================] - 2s 232us/step - loss: 0.0235 - accuracy: 0.9945 - val_loss: 27.5444 - val_accuracy: 0.2526\n",
      "Epoch 85/100\n",
      "6904/6904 [==============================] - 1s 184us/step - loss: 0.0206 - accuracy: 0.9949 - val_loss: 27.6869 - val_accuracy: 0.2526\n",
      "Epoch 86/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0268 - accuracy: 0.9942 - val_loss: 28.0834 - val_accuracy: 0.2526\n",
      "Epoch 87/100\n",
      "6904/6904 [==============================] - 2s 222us/step - loss: 0.0252 - accuracy: 0.9941 - val_loss: 28.4322 - val_accuracy: 0.2526\n",
      "Epoch 88/100\n",
      "6904/6904 [==============================] - 1s 184us/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 28.7858 - val_accuracy: 0.2526\n",
      "Epoch 89/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 29.0756 - val_accuracy: 0.2526\n",
      "Epoch 90/100\n",
      "6904/6904 [==============================] - 1s 187us/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 29.1817 - val_accuracy: 0.2526\n",
      "Epoch 91/100\n",
      "6904/6904 [==============================] - 2s 218us/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 29.5590 - val_accuracy: 0.2526\n",
      "Epoch 92/100\n",
      "6904/6904 [==============================] - 1s 176us/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 30.5063 - val_accuracy: 0.2513\n",
      "Epoch 93/100\n",
      "6904/6904 [==============================] - 1s 183us/step - loss: 0.0218 - accuracy: 0.9944 - val_loss: 30.2171 - val_accuracy: 0.2526\n",
      "Epoch 94/100\n",
      "6904/6904 [==============================] - 2s 279us/step - loss: 0.0242 - accuracy: 0.9946 - val_loss: 30.9920 - val_accuracy: 0.2526\n",
      "Epoch 95/100\n",
      "6904/6904 [==============================] - 1s 200us/step - loss: 0.0186 - accuracy: 0.9946 - val_loss: 31.8248 - val_accuracy: 0.2513\n",
      "Epoch 96/100\n",
      "6904/6904 [==============================] - 1s 193us/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 32.0282 - val_accuracy: 0.2526\n",
      "Epoch 97/100\n",
      "6904/6904 [==============================] - 1s 214us/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 31.7894 - val_accuracy: 0.2513\n",
      "Epoch 98/100\n",
      "6904/6904 [==============================] - 2s 218us/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 32.3099 - val_accuracy: 0.2513\n",
      "Epoch 99/100\n",
      "6904/6904 [==============================] - 1s 174us/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 32.3013 - val_accuracy: 0.2526\n",
      "Epoch 100/100\n",
      "6904/6904 [==============================] - 2s 241us/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 32.8275 - val_accuracy: 0.2526\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7672/7672 [==============================] - 0s 46us/step\n",
      "Test accuracy: 0.9211418032646179\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/textclassify.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
